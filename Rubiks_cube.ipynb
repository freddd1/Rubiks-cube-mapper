{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer Vision - Fall 2020\n",
    "\n",
    "\n",
    "## <span style=\"color:blue\">Final Project - Rubik's cube mapper </span>\n",
    "\n",
    "In this project we built a Rubikâ€™s Cube mapper using classic computer vision techniques.\n",
    "\n",
    "\n",
    "## Submission Notes:\n",
    "\n",
    "1. In this project we used `python 3`, `numpy 1.18.5` and `cv2 4.4.0`\n",
    "2. In order to use the code you should have a webcam and a Rubik's cube\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "1. Run all the notebook and your webcam will open.\n",
    "2. follow the written instructions. \n",
    "    1. find a good place to place the camera and the cube.\n",
    "    2. Calibrate the colors by double clicking on the color on the screen\n",
    "    3. Follow the printed instructions on how to rotate the cube\n",
    "    4. If all went well you will see a printed version of the cube.\n",
    "3. `active_cam` is the main function and has 1 parameter called `debug`.\n",
    "    The default is `False`, but if `debug=True` you will see all of \"behind the scene\" screen and how the algorithm is actually working\n",
    "4. If you want to recalibrate the colors you should restart the kernel and run all cells\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.7.7\n",
      "Numpy version:  1.18.5\n",
      "cv2 version:  4.4.0\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"cv2 version: \", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global param\n",
    "\n",
    "\n",
    "clicked = False\n",
    "frame = None\n",
    "\n",
    "COLOR_NAMES = ['red', 'blue', 'green', 'yellow', 'orange', 'white']\n",
    "COLOR_SIGNS = ['R', 'B', 'G', 'Y', 'O', 'W']\n",
    "COLOR_IDX = 0\n",
    "\n",
    "# COLOR_CALIBRATION dictionary that will hold the calibrated colors\n",
    "# in the form of -> color name : 30x30x3 sample of the color (HSV) \n",
    "COLOR_CALIBRATION = {}\n",
    "\n",
    "# COLOR_RANGE dictionary based on the COLOR_CALIBRATION\n",
    "# that will hold for each color name his threshold of HSV values (lower and upper threshold)\n",
    "# in the form of -> color name : (lower, upper)\n",
    "# where lower and upper are hsv values -> (a, b ,c)\n",
    "COLOR_RANGE = {}\n",
    "\n",
    "\n",
    "COLOR_VERDICT = {}\n",
    "\n",
    "\n",
    "\n",
    "# text style\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (50,50)\n",
    "fontScale = 1\n",
    "fontColor = (255,255,255)\n",
    "lineType = 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_res(frame, y, x):\n",
    "    \"\"\"\n",
    "    Update the COLOR_CALIBRATION dictionary global param.\n",
    "    where the key is the color name and the value\n",
    "    is 30x30x3 sample of the color (in HSV format)\n",
    "    \n",
    "    Input:\n",
    "    - frame: from the camera stream\n",
    "    - y: with range of sub frame taken for color calibration  \n",
    "    - x: high range of sub frame taken for color calibration \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    pos = 15\n",
    "    COLOR_CALIBRATION[COLOR_NAMES[COLOR_IDX]] = []\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) # generates an hsv version of frame and \n",
    "                                                 # stores it in the hsv image variable\n",
    "    COLOR_CALIBRATION[COLOR_NAMES[COLOR_IDX]] = hsv[y-pos:y+pos, x-pos:x+pos]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_click(event, x, y, flags, param):\n",
    "    \"\"\"\n",
    "    the function is global action listener for mouse click that active  \"update_res\" on the calibration stage\n",
    "    and also confirm validation of click on frame \n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - event: action listener of mouse click on the frame\n",
    "    - x: high range of sub frame taken for color calibration \n",
    "    - y: with range of sub frame taken for color calibration \n",
    " \n",
    "\n",
    "    \"\"\"\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK and frame is not None:\n",
    "        global clicked\n",
    "        clicked = True\n",
    "        update_res(frame, y, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_calibration(img):\n",
    "    \"\"\"\n",
    "    the function activating the calibration stage every time a color is updated\n",
    "    the user receive message on the screen what the color he need to calibrate by clicking to proper color \n",
    "    the function will continue until all 6 colors with be calibrated\n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    - img: the frame from camera stream \n",
    "    -click: actionlistener of mouse click \n",
    "    \n",
    "    output:\n",
    "    -Updated :Global COLOR_IDX : count number of colors been updated \n",
    "    -frame +putText: frame with color need to calibrated\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    global COLOR_IDX\n",
    "    global clicked\n",
    "    if COLOR_IDX < 6:\n",
    "        cv2.putText(img, COLOR_NAMES[COLOR_IDX].title(),(50,50),2,0.8,(255,255,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    if (clicked):\n",
    "        clicked=False\n",
    "        COLOR_IDX += 1\n",
    "    return\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colors_range():\n",
    "    \"\"\"\n",
    "    create the COLOR_RANGE dictionary global param based on\n",
    "    the values in COLOR_CALIBRATION\n",
    "    the key is the color name\n",
    "    the value is (lower, upper) thresholds for HSV color range\n",
    "    example -> 'W'  :  ((  0,   0, 215), (179,  55, 255))\n",
    "\n",
    "    \"\"\"\n",
    "    global COLOR_RANGE\n",
    "    \n",
    "    # HSV values in the form of (a,b,c)\n",
    "    # where 0 <=  a  <= 179\n",
    "    #       0 <= b,c <= 255\n",
    "    \n",
    "    # factores to increase the range of the threshold\n",
    "    factor_a = 10\n",
    "    factor_bc = 25\n",
    "    \n",
    "    for color, values in COLOR_CALIBRATION.items():\n",
    "        mins = values.min(axis=1).min(axis=0)\n",
    "        maxs = values.max(axis=1).max(axis=0)\n",
    "\n",
    "        a, b ,c = mins\n",
    "        a = max(0, a-factor_a)\n",
    "        b = max(0, b-factor_bc)\n",
    "        c = max(0, c-factor_bc)\n",
    "        min_th = (a, b, c)\n",
    "        \n",
    "        a, b ,c = maxs\n",
    "        a = min(179, a+factor_a)\n",
    "        b = min(255, b+factor_bc)\n",
    "        c = min(255, c+factor_bc)\n",
    "        max_th = (a, b, c)\n",
    "        \n",
    "        COLOR_RANGE[color[0].upper()] = (min_th, max_th)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_cube(image, thresh=175):\n",
    "    \"\"\"\n",
    "    given an image the function will find the cube shape in its contour.\n",
    "    \n",
    "    Input:\n",
    "    - image: the original frame\n",
    "    - thresh: threshold \n",
    "    \n",
    "    Returns:\n",
    "    - original_contour: the original frame with the cube contour on top of it (image)\n",
    "    - cropped: the cropped contour from the original image (image)\n",
    "    - buffer: (x, y) the shift of the contour. will help draw the contours on the original frame\n",
    "\n",
    "    \"\"\"  \n",
    "    orignel = image.copy()\n",
    "    buffer = 0, 0\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "        \n",
    "    grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    grayImage = 255-grayImage\n",
    "\n",
    "    grayImage = cv2.threshold(grayImage, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    \n",
    "    opening = cv2.morphologyEx(grayImage, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "    dilation = cv2.dilate(opening, kernel, iterations=3)\n",
    "    closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    " \n",
    "    contours, hierarchy = cv2.findContours(closing, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "\n",
    "    \n",
    "    if cntsSorted != []:\n",
    "        x, y, w, h = cv2.boundingRect(cntsSorted[0])\n",
    "\n",
    "        original_contour = cv2.rectangle(orignel, (x,y), (x+w,y+h), (0,255,0), 2)    \n",
    "\n",
    "        cropped = image[y: y+h, x: x+w]\n",
    "\n",
    "\n",
    "        # buffer var helps as draw the contoures on the main frame\n",
    "        buffer = x, y\n",
    "    \n",
    "    # unmark to see the filltered  (black and white frame)\n",
    "#     cv2.imshow('filter_draw', filter_draw)\n",
    "\n",
    "    blackwhite = cv2.cvtColor(closing, cv2.COLOR_GRAY2RGB)\n",
    "    blackwhite = cv2.rectangle(blackwhite, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "\n",
    "#     # unmark to add text of frame size to the cropped image\n",
    "#     cv2.putText(cropped, \n",
    "#                 str(cropped.shape),\n",
    "#                 bottomLeftCornerOfText, \n",
    "#                 font, \n",
    "#                 fontScale,\n",
    "#                 fontColor,\n",
    "#                 lineType)\n",
    "\n",
    "\n",
    "    return  original_contour, cropped, buffer, blackwhite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colors_mask(image):\n",
    "    \"\"\"\n",
    "    the function will create a mask based on the colors in COLOR_RANGE\n",
    "    \n",
    "    Input:\n",
    "    - image: the frame on which we want to create the mask\n",
    "    \n",
    "    Return:\n",
    "    - result: the input image masked (the original pixels only where the mask is)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    original = image.copy()\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros((image.shape[0],image.shape[1]), dtype=np.uint8)\n",
    "    \n",
    "    for color, (lower, upper) in COLOR_RANGE.items():\n",
    "        lower = np.array(lower, dtype=np.uint8)\n",
    "        upper = np.array(upper, dtype=np.uint8)\n",
    "        \n",
    "        # mark all the pixels that are in the range of the thresholds\n",
    "        color_mask = cv2.inRange(image, lower, upper)\n",
    "        mask = mask + color_mask\n",
    "        \n",
    "        # returns the original frame masked\n",
    "        result = cv2.bitwise_or(original, original, mask=mask)\n",
    "        \n",
    "        #unmark to show the mask\n",
    "#         cv2.imshow('color_mask_binary', mask)\n",
    "        \n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(image, retrun_image=True):\n",
    "    \"\"\"\n",
    "    the function will find the 9 largest contours in the image\n",
    "    and returns list of their positions ordered LEFT TO RIGHT and TOP TO BOTTOM\n",
    "    \n",
    "    Input:\n",
    "    - image: the frame (after colors_mask)\n",
    "    - return_image: if True will return the image with the number contours on it\n",
    "                    (help for debugging)\n",
    "    \n",
    "    Return:\n",
    "    - final_list: list of the contours positions. each item in the list is (x, y, hight, width)\n",
    "    - image: the input image with the 9 numbered contours on it\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    contours_positions = []\n",
    "    lst = []\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
    "    \n",
    "    contours_positions = [cv2.boundingRect(contor) for contor in cntsSorted[:9]]\n",
    "    \n",
    "    \n",
    "    # order the contours LEFT TO RIGHT and TOP TO BUTTOM\n",
    "    #           1 2 3\n",
    "    #           4 5 6\n",
    "    #           7 8 9\n",
    "    \n",
    "    y_vals = sorted([l[1] for l in contours_positions])\n",
    "    x_vals = sorted([l[0] for l in contours_positions])\n",
    "    \n",
    "    top_row = []\n",
    "    mid_row = []\n",
    "    low_row = []\n",
    "    for l in contours_positions:\n",
    "        if l[1] in y_vals[:3]:\n",
    "            top_row.append(l)\n",
    "        elif l[1] in y_vals[3:6]:\n",
    "            mid_row.append(l)\n",
    "        else:\n",
    "            low_row.append(l)\n",
    "    \n",
    "    top_row = sorted(top_row, key=lambda x: x[0])\n",
    "    mid_row = sorted(mid_row, key=lambda x: x[0])\n",
    "    low_row = sorted(low_row, key=lambda x: x[0])\n",
    "    \n",
    "    final_list = top_row + mid_row + low_row\n",
    "     \n",
    "    if retrun_image:\n",
    "        for i in range(len(final_list)):\n",
    "            item = final_list[i]\n",
    "            x, y, w, h = contours_positions[i]\n",
    "            image = cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "            cv2.putText(image, str(i+1), (item[0]+10, item[1]+10) ,font, fontScale,  fontColor, lineType)\n",
    "        return final_list, image\n",
    "    \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(image, contours_positions):\n",
    "    \"\"\"\n",
    "    the function will drow the 9 contours on the image\n",
    "    \n",
    "    Input:\n",
    "    - image: the image on which we want to print the contours\n",
    "    - contours_positions: list of the contours positions. each item -> (x, y, w, h)\n",
    "    \"\"\"\n",
    "    for x, y, w, h in contours_positions:\n",
    "        image = cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_specific_color(contour):\n",
    "    \"\"\"\n",
    "    the function will find the color of given contour (which is image)\n",
    "    the colors are based on COLOR_RANGE\n",
    "    Input:\n",
    "    - contour: the image on which we want find her color\n",
    "    \n",
    "    Return:\n",
    "    - decided_color_label: the sign of the decided color. if could not found and color from\n",
    "                            COLOR_SIGNS will return 'X'\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert frame from RGB to HSV\n",
    "    try:\n",
    "        contour = cv2.cvtColor(contour, cv2.COLOR_BGR2HSV)\n",
    "    except:\n",
    "        return 'X'\n",
    "    \n",
    "    pixels_number = contour.shape[0]*contour.shape[1]\n",
    "    decided_color_label = 'X'\n",
    "    decided_color_value = 0\n",
    "    \n",
    "    # the ratio will idicate which color has the most pixels in the contour\n",
    "    # we will find the biggest color ratio and return it\n",
    "    ratio = 0\n",
    "    \n",
    "    for color, (lower, upper) in COLOR_RANGE.items():\n",
    "        lower = np.array(lower, dtype=np.uint8)\n",
    "        upper = np.array(upper, dtype=np.uint8)\n",
    "        try:\n",
    "            mask = cv2.inRange(contour, lower, upper)\n",
    "            ratio = (mask == 255).sum() / pixels_number\n",
    "        except:\n",
    "            mask = np.zeros(contour.shape)\n",
    "\n",
    "        if ratio > decided_color_value:\n",
    "            decided_color_value = ratio\n",
    "            decided_color_label = color[0].upper()\n",
    "    \n",
    "    return decided_color_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_colors(frame, contours_positions):\n",
    "    \n",
    "    \"\"\"\n",
    "    the function will find the colors on the contours in the frame\n",
    "    it will sample each contour from the frame and find his color using find_specific_color function\n",
    "    \n",
    "    Input:\n",
    "    - frame: the frame on which we want to find the colors\n",
    "    - contours_positions: list of the contours_positions \n",
    "    Return:\n",
    "    - frame: the input frame with the color classification printed o it\n",
    "    - classified: string (length 9) represent the colors that were found in the frame\n",
    "\n",
    "    \"\"\"\n",
    "    colors_names = []\n",
    "    s = 5\n",
    "    for x, y, w, h in contours_positions:\n",
    "        contour = frame[y+s: y+h-s, x+s: x+w-s]\n",
    "        name = find_specific_color(contour)\n",
    "        colors_names.append(name)\n",
    "\n",
    "        \n",
    "    classified = \"\".join(colors_names)\n",
    "    \n",
    "    \n",
    "    for i in range(len(colors_names)):\n",
    "        x, y, w, h = contours_positions[i]\n",
    "#         image = cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        frame = cv2.putText(frame, colors_names[i], (x, y) ,font, fontScale,  fontColor, lineType)\n",
    "    return frame, classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_freq(freq_list):\n",
    "    \"\"\"\n",
    "    the function will find the most frequent string (that represent the colors verdicts)\n",
    "    in given list\n",
    "    \n",
    "    Input:\n",
    "    - freq_list: list with string representing the colors verdicts\n",
    "    Return:\n",
    "        prints the user instruction and eventually the virtual cube\n",
    "\n",
    "    \"\"\"\n",
    "    unique, pos = np.unique(np.array(freq_list), return_inverse=True)\n",
    "    counts = np.bincount(pos)\n",
    "    maxpos = counts.argmax()\n",
    "    verdict = unique[maxpos]\n",
    "    \n",
    "    # checks that the output is valid\n",
    "    # if yes returns the face and the verdict\n",
    "    # otherwise return 'X' and verdict\n",
    "    # 'X' represnt failure\n",
    "    \n",
    "    if len(verdict) == 9 and 'X' not in verdict:\n",
    "        face = verdict[4]\n",
    "        return face, verdict\n",
    "    else:\n",
    "        return 'X', verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cube_string(order):\n",
    "    \"\"\"\n",
    "    the function will print representation of the cube.\n",
    "    The instructions for the user are:\n",
    "    rotate left 4 times, then up 1 time and then down 2 times. \n",
    "    on the right cube you can see the order of the instruction.\n",
    "    \n",
    "        WWW                   555\n",
    "        WWW                   555\n",
    "        WWW                   555\n",
    "    OOO GGG RRR BBB       111 444 333 222 \n",
    "    OOO GGG RRR BBB       111 444 333 222\n",
    "    OOO GGG RRR BBB       111 444 333 222\n",
    "        YYY                   666\n",
    "        YYY                   666\n",
    "        YYY                   666\n",
    "    \n",
    "    Input:\n",
    "    - order:list in length 6 that represent the order of the colors\n",
    "    \"\"\"\n",
    "    global COLOR_VERDICT\n",
    "    \n",
    "    strings = [COLOR_VERDICT[c] for c in order]\n",
    "    \n",
    "    for i in range(3):\n",
    "        print('    ' + strings[4][i*3:(i+1)*3])\n",
    "\n",
    "    temp = [strings[:-2][0], strings[:-2][3], strings[:-2][2], strings[:-2][1]]\n",
    "    for i in range(3):\n",
    "        string = ''\n",
    "        for l in temp:\n",
    "            string += (l[i*3:(i+1)*3])+ ' '\n",
    "        print(string)\n",
    "            \n",
    "    \n",
    "    for i in range(3):\n",
    "        print('    ' + strings[5][i*3:(i+1)*3])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_cam(debug=False):\n",
    "    \"\"\"\n",
    "    This is the main function. it will open the video camera, capture the video and call all other functions\n",
    "    \n",
    "    Input:\n",
    "    - debug: if True will show all \"behind the scenes\" processing\n",
    "\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame', mouse_click)\n",
    "\n",
    "    try:\n",
    "        \n",
    "        verdicts = []\n",
    "        temp_values = ''\n",
    "        global order\n",
    "        order = ['X','X','X','X','X','X']\n",
    "        order_idx = 0\n",
    "        \n",
    "        while(True):\n",
    "            global frame\n",
    "            global COLOR_VERDICT\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            stage_calibration(frame)\n",
    "        \n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            if len(COLOR_CALIBRATION) < 6:\n",
    "                continue\n",
    "                          \n",
    "            create_colors_range()       \n",
    "                    \n",
    "            # crop the image\n",
    "            frame_contour, frame_cropped, buffer, frame_blackwhite_mask = crop_cube(frame, thresh=170)\n",
    "            \n",
    "            if debug:\n",
    "                cv2.imshow('frame_contour', frame_contour)\n",
    "                cv2.imshow('frame_cropped', frame_cropped)\n",
    "                cv2.imshow('frame_blackwhite_mask', frame_blackwhite_mask)\n",
    "\n",
    "            # create the color mask\n",
    "            frame_cropped_colors_mask = colors_mask(frame_cropped)\n",
    "            \n",
    "            if debug: \n",
    "                cv2.imshow('frame_cropped_colors_mask', frame_cropped_colors_mask)\n",
    "\n",
    "            # find contours using the color mask\n",
    "            contours_positions_cropped, frame_cropped_contours = find_contours(frame_cropped_colors_mask)\n",
    "            \n",
    "            if debug:\n",
    "                cv2.imshow('frame_cropped_contours', frame_cropped_contours)\n",
    "            \n",
    "            # create positions list considering the main frame\n",
    "            contours_positions = [(buffer[0]+x, buffer[1]+y, h, w) for x, y, h, w in contours_positions_cropped]\n",
    "            \n",
    "            # show the contours on the original frame\n",
    "            frame = draw_contours(frame, contours_positions)\n",
    "            \n",
    "            frame_colors_verdicts, colors_verdict = find_colors(frame, contours_positions)\n",
    "            cv2.imshow('frame', frame_colors_verdicts)\n",
    "            \n",
    "            verdicts.append(colors_verdict)\n",
    "            # every 35 stream of frames (betch) choose the classifaction\n",
    "            # there is some tests to make sure the input is valid\n",
    "            # if tow betchs are the same we will appned the clasiffcation verdict\n",
    "            if len(verdicts) == 35:\n",
    "                face, values = find_most_freq(verdicts)\n",
    "                if face != 'X': # make sure we found a real color as face\n",
    "                    if temp_values == values: \n",
    "                        if face not in COLOR_VERDICT:\n",
    "                            COLOR_VERDICT[face] = values\n",
    "                            order[order_idx] = face\n",
    "                            order_idx += 1\n",
    "                            print(f'found faces: {order}')\n",
    "                        \n",
    "                        # in this part there is prints guding the user\n",
    "                        remain_colors = set(COLOR_SIGNS)-set(COLOR_VERDICT.keys())\n",
    "                        if len(remain_colors) > 2: \n",
    "                            print('rotate left')\n",
    "                        elif len(remain_colors) == 2:\n",
    "                            print('rotate up')\n",
    "                        elif len(remain_colors) == 1:\n",
    "                            print('rotate down twice')\n",
    "                        else:\n",
    "                            create_cube_string(order)\n",
    "                            break\n",
    "                    else:\n",
    "                        print('wait')\n",
    "                        \n",
    "                temp_values = values\n",
    "                verdicts = []\n",
    "                \n",
    "                \n",
    "    finally:\n",
    "        # When everything done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait\n",
      "found faces: ['Y', 'X', 'X', 'X', 'X', 'X']\n",
      "rotate left\n",
      "rotate left\n",
      "wait\n",
      "found faces: ['Y', 'O', 'X', 'X', 'X', 'X']\n",
      "rotate left\n",
      "rotate left\n",
      "rotate left\n",
      "wait\n",
      "found faces: ['Y', 'O', 'W', 'X', 'X', 'X']\n",
      "rotate left\n",
      "rotate left\n",
      "rotate left\n",
      "wait\n",
      "found faces: ['Y', 'O', 'W', 'R', 'X', 'X']\n",
      "rotate up\n",
      "rotate up\n",
      "rotate up\n",
      "rotate up\n",
      "rotate up\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "found faces: ['Y', 'O', 'W', 'R', 'G', 'X']\n",
      "rotate down twice\n",
      "rotate down twice\n",
      "rotate down twice\n",
      "wait\n",
      "wait\n",
      "wait\n",
      "found faces: ['Y', 'O', 'W', 'R', 'G', 'B']\n",
      "    YOY\n",
      "    YGW\n",
      "    YYB\n",
      "GBG OGW RBO BWR \n",
      "OYW GRO GWR GOB \n",
      "RRO BYG ORR BRW \n",
      "    WOW\n",
      "    WBY\n",
      "    GBY\n"
     ]
    }
   ],
   "source": [
    "active_cam(debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}